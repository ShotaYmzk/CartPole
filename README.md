# CartPole ビジュアルサンドボックス

リアルタイムで動作する強化学習環境のデモンストレーションアプリケーションです。CartPole問題を通じて、機械学習の一分野である**強化学習**の基本概念を視覚的に学ぶことができます。

## 🎯 このプログラムは何をしているのか？

### CartPole問題とは
CartPole（カートポール）は、強化学習の世界で最も有名な**制御問題**の一つです：

- **カート**：水平に移動できる台車
- **ポール**：カートの上に立てられた棒（逆立ち振り子）
- **目標**：ポールを倒さないように、カートを左右に動かしてバランスを保つ

これは、人間が手のひらの上で棒を立てて歩くのと似た問題です。

### 物理シミュレーション
このプログラムでは、以下の物理法則を数値計算で再現しています：

- **重力**：ポールを倒そうとする力（9.8 m/s²）
- **慣性**：カートとポールの質量による運動
- **角運動**：ポールの回転運動
- **摩擦**：現実的な動作のための抵抗

## 🧠 強化学習とは？

**強化学習**は、AIが「試行錯誤」を通じて最適な行動を学習する手法です：

1. **エージェント**（AI）が**環境**（CartPole）を観察
2. **行動**（左右のどちらに力を加えるか）を選択
3. **報酬**（ポールが倒れなければ+1点）を受け取る
4. この繰り返しで、より良い**方策**（行動パターン）を学習

### 本プログラムの学習アルゴリズム
- **REINFORCE**（方策勾配法）を使用
- 簡単なニューラルネットワーク（入力4→隠れ層8→出力2）
- リアルタイムで重みが更新され、性能が向上していく様子を観察可能

## 🔍 何が可視化されているのか？

### 1. 物理シミュレーション画面
- **カート**：黒い四角形（左右に移動）
- **ポール**：青いグラデーションの棒（回転）
- **軌道**：カートの移動範囲（青い安全ゾーン）
- **影**：リアルな3D効果

### 2. ニューラルネットワーク可視化
- **ノード**：ニューロン（神経細胞のモデル）
  - 入力層：x（位置）、xDot（速度）、theta（角度）、thetaDot（角速度）
  - 隠れ層：8個の中間処理ユニット
  - 出力層：左（-1）、右（+1）の行動確率
- **接続線**：重み（シナプスの強さ）
  - 青：正の重み（促進）
  - ピンク：負の重み（抑制）
  - 太さ：重みの大きさ

### 3. 学習進捗メトリクス
- **ステップ数**：ポールを支え続けた時間
- **エピソード数**：ゲーム回数
- **報酬**：獲得した点数
- **移動平均**：学習の安定性指標

## 🎮 何ができるのか？

### 制御方法の比較
1. **ニューラル**：AIが学習した方策で制御
2. **ヒューリスティック**：人間が設計したルールベース制御
3. **ランダム**：完全にランダムな行動（比較用）

### インタラクティブ機能
- **開始/一時停止**：シミュレーションの制御
- **リセット**：初期状態に戻す
- **ネットワークリセット**：AIの学習をゼロから開始
- **リアルタイム学習**：動作中にAIが賢くなっていく様子を観察

### 学習観察
- 最初はランダムに近い動作
- 徐々に安定した制御を学習
- ネットワークの重みの変化をリアルタイム表示
- 学習曲線（報酬の推移）をグラフィカルに確認

## 🚀 はじめ方

### 1. 開発環境のセットアップ

```bash
# 依存関係のインストール
npm install
# または
yarn install

# 開発サーバーの起動
npm run dev
# または
yarn dev
```

### 2. アプリケーションの起動
ブラウザで [http://localhost:3000](http://localhost:3000) を開いてください。

### 3. 使い方
1. 「開始」ボタンをクリック
2. 制御方法を切り替えて比較
3. ニューラルモードで学習の様子を観察
4. ネットワーク可視化で重みの変化を確認

## 🎓 学習のポイント

### 物理学の観点
- **運動方程式**：F = ma（ニュートンの第二法則）
- **角運動量**：回転運動の物理
- **制御理論**：フィードバック制御の基礎

### 機械学習の観点
- **教師なし学習**：正解データなしで学習
- **試行錯誤学習**：失敗から学ぶメカニズム
- **最適化**：勾配降下法による重み更新
- **確率的方策**：行動選択の確率分布

### プログラミングの観点
- **数値計算**：物理シミュレーションの実装
- **リアルタイム処理**：60FPSでの計算と描画
- **データ構造**：状態管理とメモリ効率
- **関数型プログラミング**：React Hooksの活用

## 🔧 技術仕様

- **フレームワーク**：Next.js 14 (React)
- **言語**：TypeScript
- **描画**：HTML5 Canvas
- **スタイリング**：Tailwind CSS
- **物理エンジン**：カスタム実装（オイラー法）
- **機械学習**：REINFORCE アルゴリズム

## 📚 参考資料

強化学習について詳しく学びたい方は：

- [Sutton & Barto: Reinforcement Learning: An Introduction](http://incompleteideas.net/book/the-book.html)
- [OpenAI Gym - CartPole](https://gymnasium.farama.org/environments/classic_control/cart_pole/)
- [Deep Reinforcement Learning Course](https://huggingface.co/learn/deep-rl-course)

## 🤝 貢献

このプロジェクトへの貢献を歓迎します！Issue の報告や Pull Request をお気軽にお送りください。
